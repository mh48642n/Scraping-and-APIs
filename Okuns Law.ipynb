{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "![](https://media.giphy.com/media/xT9C25UNTwfZuk85WP/giphy-downsized-large.gif)\n",
    "\n",
    "Remember the rules of ~Fight~ Code Club:\n",
    "1. ALWAYS DOCUMENT\n",
    "2. Cite resources that you use (paste links)\n",
    "3. Include the names people who you worked with\n",
    "4. Be neat and organized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and Clean data\n",
    "\n",
    "Based on you proposal, scrape or collect your data:\n",
    "\n",
    "1. One variable must be either: (40 pts)\n",
    "    1. scraped from the web OR;\n",
    "    2. collected from an API AND you must create one new variable that is \"new\" to the best of your knowledge (combination of other variables representing something new).\n",
    "\n",
    "2. You must have at least 3 variables, but you may include as many as you want into you final dataset. Likely, you will want to include more to make graphs and regressions. (30pts)\n",
    "\n",
    "3. You must *be able* to run a regression that makes some sense with this data (the regression doesn't have to be a complete model). Briefly describe one regression you would run with your variables. (**DO NOT** run a regression, yet). (15pts)\n",
    "\n",
    "4. You must have one combined and cleaned dataset (15 pts)\n",
    "\n",
    "You must submit one python notebook on how you scraped/gathered data from an api, and how you combined and cleaned you data. I should be able to run your code and reproduce your final data set.  \n",
    "\n",
    "The other variables that you choose to include do not have to be collected by API or webscraped, but you do have to combine the files and clean the dataset with python.\n",
    "\n",
    "Thus, you must submit:\n",
    "- Your finalized data set (only one) (note: you may add more variables in the future).\n",
    "- Your documented python notebook\n",
    "- Any associated data files needed to produce the final dataset.\n",
    "\n",
    "You will be evaluated on:\n",
    "- Completeness of the data\n",
    "- Quality of the code \n",
    "- The creativity of the new variable/webscraped data you gather\n",
    "\n",
    "Be sure to upload ALL associated files for your code to run. I will run your code from beginning to end - make it easy for me to replicate your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables \n",
    "<span style=\"background-color: #FFFF00\">Done</span>\n",
    "\n",
    "1.Outputs and employment from different parts of the manufacturing sector(maybe)\n",
    "\n",
    "2.CPI - Urban and All Not Including Food and Energy <span style=\"background-color: #FFFF00\">Done</span>\n",
    "\n",
    "3.National Income Level <span style=\"background-color: #FFFF00\">Done</span>\n",
    "\n",
    "4.Demand for raw materials(Baltic Dry Index)\n",
    "\n",
    "5.General Monthly Employment numbers and monthly GDP across at least 20 years <span style=\"background-color: #FFFF00\">Done</span>\n",
    "\n",
    "6.Cost of capital\n",
    "\n",
    "7.Measure for investment demand for manufacturing businesses\n",
    "\n",
    "8.Monetary Policy shifts expectations and reality\n",
    "\n",
    "9.Technology Index that controls for the increase of innovation in the economy\n",
    "\n",
    "10.Michigan State’s Consumer Price Index <span style=\"background-color: #FFFF00\">Done</span>\n",
    "\n",
    "[Merging help](https://stackoverflow.com/questions/23668427/pandas-three-way-joining-multiple-dataframes-on-columns)\n",
    "\n",
    "Considering using this: [NBER Manufacturing Database](https://www.nber.org/research/data/nber-ces-manufacturing-industry-database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing Fred API\n",
    "[Fred API Documentation](https://fred.stlouisfed.org/docs/api/fred/)\n",
    "\n",
    "API KEY: 565e55b6fbd720965afae15454629fae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages needed\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes request to connect to api for Federal Funds Rate series\n",
    "res = requests.get(\"https://api.stlouisfed.org/fred/series/observations?series_id=DFF&api_key=565e55b6fbd720965afae15454629fae&file_type=json\")\n",
    "json_ffr = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary to put data \n",
    "dt_fr = {}\n",
    "dt_fr[\"dates\"] = []\n",
    "dt_fr[\"ff_rate\"] = []\n",
    "\n",
    "#loops through observations and appends observed days to the dataframe\n",
    "for y in range(0, len(json_ffr[\"observations\"])):\n",
    "    dt_fr[\"dates\"].append(json_ffr[\"observations\"][y].get('date'))\n",
    "    dt_fr[\"ff_rate\"].append(json_ffr[\"observations\"][y].get('value'))\n",
    "\n",
    "#Converts dictionary to dataframe and making dates into datetime type and rates into numeric\n",
    "dt_fr = pd.DataFrame(dt_fr)\n",
    "dt_fr[\"dates\"] = pd.to_datetime(dt_fr[\"dates\"])\n",
    "dt_fr[\"ff_rate\"] = pd.to_numeric(dt_fr[\"ff_rate\"], errors = \"coerce\")\n",
    "\n",
    "#subsets data and resets the index\n",
    "dt_fr = dt_fr[dt_fr[\"dates\"] >= \"1998-01-01\"].reset_index(drop = True, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>ff_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-02-01</td>\n",
       "      <td>5.557419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>5.505714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>5.493548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-05-01</td>\n",
       "      <td>5.445333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>5.488710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>5.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>5.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>5.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>5.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>5.330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates   ff_rate\n",
       "0   1998-02-01  5.557419\n",
       "1   1998-03-01  5.505714\n",
       "2   1998-04-01  5.493548\n",
       "3   1998-05-01  5.445333\n",
       "4   1998-06-01  5.488710\n",
       "..         ...       ...\n",
       "311 2024-01-01  5.330000\n",
       "312 2024-02-01  5.330000\n",
       "313 2024-03-01  5.330000\n",
       "314 2024-04-01  5.330000\n",
       "315 2024-05-01  5.330000\n",
       "\n",
       "[316 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets date as index to allow groupby of rates my month\n",
    "dt_fr_avg = dt_fr.set_index(dt_fr[\"dates\"]).groupby(pd.Grouper(freq = \"M\")).mean()\n",
    "\n",
    "#Shifts the dates by one day to make it easier to merge and reset index\n",
    "#shifting makes January 31st 2023 into February 1st 2023 instead\n",
    "dt_fr_avg = dt_fr_avg.shift(freq = '1d')[[\"ff_rate\"]].reset_index(0)\n",
    "dt_fr_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BLS API \n",
    "[BLS API Documentation](https://www.bls.gov/developers/api_signature_v2.htm#parameters)\n",
    "\n",
    "API KEY: ee2f076f1d254305bc09f42aa498afab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'REQUEST_SUCCEEDED',\n",
       " 'responseTime': 29,\n",
       " 'message': [],\n",
       " 'Results': {'survey': [{'survey_abbreviation': 'AP',\n",
       "    'survey_name': 'Consumer Price Index - Average Price Data'},\n",
       "   {'survey_abbreviation': 'BD',\n",
       "    'survey_name': 'Business Employment Dynamics'},\n",
       "   {'survey_abbreviation': 'BG',\n",
       "    'survey_name': 'Collective Bargaining Agreements-State and Local Government'},\n",
       "   {'survey_abbreviation': 'BP',\n",
       "    'survey_name': 'Collective Bargaining Agreements-Private Sector'},\n",
       "   {'survey_abbreviation': 'CB',\n",
       "    'survey_name': 'Biennial Nonfatal Case and Demographic numbers and rates: selected characteristics'},\n",
       "   {'survey_abbreviation': 'CC',\n",
       "    'survey_name': 'Employer Costs for Employee Compensation'},\n",
       "   {'survey_abbreviation': 'CD',\n",
       "    'survey_name': 'Nonfatal cases involving days away from work: selected characteristics'},\n",
       "   {'survey_abbreviation': 'CE',\n",
       "    'survey_name': 'Employment, Hours, and Earnings from the Current Employment Statistics survey (National)'},\n",
       "   {'survey_abbreviation': 'CF',\n",
       "    'survey_name': 'Census of Fatal Occupational Injuries'},\n",
       "   {'survey_abbreviation': 'CH',\n",
       "    'survey_name': 'Nonfatal cases involving days away from work: selected characteristics (2003 - 2010)'},\n",
       "   {'survey_abbreviation': 'CI', 'survey_name': 'Employment Cost Index'},\n",
       "   {'survey_abbreviation': 'CM',\n",
       "    'survey_name': 'Employer Costs for Employee Compensation'},\n",
       "   {'survey_abbreviation': 'CS',\n",
       "    'survey_name': 'Nonfatal cases involving days away from work: selected characteristics (2011 forward)'},\n",
       "   {'survey_abbreviation': 'CU',\n",
       "    'survey_name': 'Consumer Price Index - All Urban Consumers'},\n",
       "   {'survey_abbreviation': 'CW',\n",
       "    'survey_name': 'Consumer Price Index - Urban Wage Earners and Clerical Workers'},\n",
       "   {'survey_abbreviation': 'CX', 'survey_name': 'Consumer Expenditure Survey'},\n",
       "   {'survey_abbreviation': 'EB', 'survey_name': 'Employee Benefits Survey'},\n",
       "   {'survey_abbreviation': 'EC', 'survey_name': 'Employment Cost Index'},\n",
       "   {'survey_abbreviation': 'EE',\n",
       "    'survey_name': 'National Employment, Hours, and Earnings'},\n",
       "   {'survey_abbreviation': 'EI', 'survey_name': 'Import/Export Price Indexes'},\n",
       "   {'survey_abbreviation': 'EN',\n",
       "    'survey_name': 'Quarterly Census of Employment and Wages'},\n",
       "   {'survey_abbreviation': 'EP',\n",
       "    'survey_name': 'Employment Projections by Industry'},\n",
       "   {'survey_abbreviation': 'EW',\n",
       "    'survey_name': 'Quarterly Census of Employment and Wages (SIC)'},\n",
       "   {'survey_abbreviation': 'FI',\n",
       "    'survey_name': 'Census of Fatal Occupational Injuries (2003 - 2010)'},\n",
       "   {'survey_abbreviation': 'FM',\n",
       "    'survey_name': 'Marital and family labor force statistics from the Current Population Survey'},\n",
       "   {'survey_abbreviation': 'FW',\n",
       "    'survey_name': 'Census of Fatal Occupational Injuries (2011 forward)'},\n",
       "   {'survey_abbreviation': 'GG', 'survey_name': 'Green Goods and Services'},\n",
       "   {'survey_abbreviation': 'GP', 'survey_name': 'Geographic Profile'},\n",
       "   {'survey_abbreviation': 'HC',\n",
       "    'survey_name': 'Nonfatal cases involving days away from work: Selected Characteristics (2002)'},\n",
       "   {'survey_abbreviation': 'HS',\n",
       "    'survey_name': 'Occupational injuries and illnesses: industry data (pre-1989)'},\n",
       "   {'survey_abbreviation': 'II',\n",
       "    'survey_name': 'Occupational injuries and illnesses: industry data'},\n",
       "   {'survey_abbreviation': 'IN',\n",
       "    'survey_name': 'International Labor Comparison'},\n",
       "   {'survey_abbreviation': 'IP', 'survey_name': 'Industry Productivity'},\n",
       "   {'survey_abbreviation': 'IS',\n",
       "    'survey_name': 'Occupational injuries and illnesses industry data'},\n",
       "   {'survey_abbreviation': 'JL',\n",
       "    'survey_name': 'Job Openings and Labor Turnover Survey'},\n",
       "   {'survey_abbreviation': 'JT',\n",
       "    'survey_name': 'Job Openings and Labor Turnover Survey'},\n",
       "   {'survey_abbreviation': 'LA',\n",
       "    'survey_name': 'Local Area Unemployment Statistics'},\n",
       "   {'survey_abbreviation': 'LE',\n",
       "    'survey_name': 'Weekly and hourly earnings data from the Current Population Survey'},\n",
       "   {'survey_abbreviation': 'LF',\n",
       "    'survey_name': 'Labor Force Statistics from the Current Population Survey (SIC)'},\n",
       "   {'survey_abbreviation': 'LI',\n",
       "    'survey_name': 'Consumer Price Index - Department Store Inventory Price Index'},\n",
       "   {'survey_abbreviation': 'LN',\n",
       "    'survey_name': 'Labor Force Statistics from the Current Population Survey'},\n",
       "   {'survey_abbreviation': 'LU',\n",
       "    'survey_name': 'Union affiliation data from the Current Population Survey'},\n",
       "   {'survey_abbreviation': 'ML', 'survey_name': 'Mass Layoff Statistics'},\n",
       "   {'survey_abbreviation': 'MP',\n",
       "    'survey_name': 'Major Sector Total Factor Productivity'},\n",
       "   {'survey_abbreviation': 'MU',\n",
       "    'survey_name': 'Consumer Price Index - All Urban Consumers (Old Series)'},\n",
       "   {'survey_abbreviation': 'MW',\n",
       "    'survey_name': 'Consumer Price Index - Urban Wage Earners and Clerical Workers (Old Series)'},\n",
       "   {'survey_abbreviation': 'NB',\n",
       "    'survey_name': 'National Compensation Survey-Benefits'},\n",
       "   {'survey_abbreviation': 'NC',\n",
       "    'survey_name': 'National Compensation Survey'},\n",
       "   {'survey_abbreviation': 'ND',\n",
       "    'survey_name': 'Producer Price Index Industry Data'},\n",
       "   {'survey_abbreviation': 'NW',\n",
       "    'survey_name': 'National Compensation Survey'},\n",
       "   {'survey_abbreviation': 'OE',\n",
       "    'survey_name': 'Occupational Employment and Wage Statistics'},\n",
       "   {'survey_abbreviation': 'OR', 'survey_name': 'Occupational Requirements'},\n",
       "   {'survey_abbreviation': 'PC',\n",
       "    'survey_name': 'Producer Price Index Industry Data'},\n",
       "   {'survey_abbreviation': 'PD',\n",
       "    'survey_name': 'Producer Price Index - Discontinued (SIC)'},\n",
       "   {'survey_abbreviation': 'PF',\n",
       "    'survey_name': 'Federal Government Productivity Index'},\n",
       "   {'survey_abbreviation': 'PI', 'survey_name': 'Industry Productivity Index'},\n",
       "   {'survey_abbreviation': 'PR',\n",
       "    'survey_name': 'Major Sector Productivity and Costs'},\n",
       "   {'survey_abbreviation': 'SA',\n",
       "    'survey_name': 'State and Area Employment, Hours, and Earnings (SIC)'},\n",
       "   {'survey_abbreviation': 'SH',\n",
       "    'survey_name': 'Occupational injuries and illnesses: industry data (1989-2001)'},\n",
       "   {'survey_abbreviation': 'SI',\n",
       "    'survey_name': 'Occupational injuries and illnesses: industry data (2002)'},\n",
       "   {'survey_abbreviation': 'SM',\n",
       "    'survey_name': 'State and Area Employment, Hours, and Earnings'},\n",
       "   {'survey_abbreviation': 'SU',\n",
       "    'survey_name': 'Consumer Price Index - Chained Consumer Price Index'},\n",
       "   {'survey_abbreviation': 'TU', 'survey_name': 'American Time Use'},\n",
       "   {'survey_abbreviation': 'WD',\n",
       "    'survey_name': 'Producer Price Index Commodity-Discontinued Series'},\n",
       "   {'survey_abbreviation': 'WM', 'survey_name': 'Wage Modeling'},\n",
       "   {'survey_abbreviation': 'WP',\n",
       "    'survey_name': 'Producer Price Index-Commodities'},\n",
       "   {'survey_abbreviation': 'WS', 'survey_name': 'Work Stoppage Data'}]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pulls all the surveys that BLS has on hand\n",
    "res = requests.get(\"https://api.bls.gov/publicAPI/v2/surveys\")\n",
    "json_survey = res.json()\n",
    "json_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function works to merge the data tables by separating them from the dataframe it is in\n",
    "#recieves the dictionary from the function called bls_json\n",
    "def bls_wrangle(value):\n",
    "    #makes list of columns that help differentiate the values after separating the data by series\n",
    "    columns = [\"man_emp\",\"core_cpi\",\"employment\", \"unemp_lvl\"]\n",
    "    \n",
    "    #converts dates to datetime and all values to numeric\n",
    "    value[\"dates\"] = pd.to_datetime(value[\"dates\"])\n",
    "    value[\"value\"] = pd.to_numeric(value[\"value\"], errors = \"coerce\")\n",
    "      \n",
    "    #divide the dataframe into four dataframes that would be combine together later\n",
    "    #the dataframe is divided by series and value column is renamed to make unique columns \n",
    "    df1 = value[value[\"series\"] == series_id[0]][[\"dates\", \"value\"]].rename(columns = {\"value\":columns[0]})\n",
    "    df2 = value[value[\"series\"] == series_id[1]][[\"dates\", \"value\"]].rename(columns = {\"value\":columns[1]})\n",
    "    df3 = value[value[\"series\"] == series_id[2]][[\"dates\", \"value\"]].rename(columns = {\"value\":columns[2]})\n",
    "    df4 = value[value[\"series\"] == series_id[3]][[\"dates\", \"value\"]].rename(columns = {\"value\":columns[3]})\n",
    "    \n",
    "    #list of the frames\n",
    "    frames = [df1, df2, df3, df4]\n",
    "        \n",
    "    #Merge on the first 2 frames and then merging sequentially through list of frames\n",
    "    frame = pd.merge(df1, df2, on = \"dates\")\n",
    "    for i in range(2, 4):\n",
    "        frame = pd.merge(frame, frames[i])    \n",
    "        frame = frame.sort_values(by = [\"dates\"])\n",
    "    \n",
    "    return(pd.DataFrame(frame))\n",
    "\n",
    "                                    \n",
    "#Places values into a dictionary with no sorting\n",
    "def bls_json(json_l):\n",
    "    #new dictionary \n",
    "    d_t = {}\n",
    "    d_t[\"dates\"] = []\n",
    "    d_t[\"series\"] = []\n",
    "    d_t[\"value\"] = []\n",
    "    \n",
    "    for i in range(0, len(json_l['Results']['series'])):\n",
    "        serie = str(json_l['Results']['series'][i].get(\"seriesID\"))\n",
    "        data = json_l['Results']['series'][i].get(\"data\") \n",
    "        for items in data:\n",
    "            d_t[\"dates\"].append((items.get(\"periodName\") + \" 01 \" + items.get(\"year\")))\n",
    "            d_t[\"value\"].append(items.get(\"value\"))\n",
    "            d_t[\"series\"].append(serie)\n",
    "\n",
    "    d_t = bls_wrangle(pd.DataFrame(d_t))\n",
    "    return(d_t)\n",
    "\n",
    "#Found these codes through the BLS Datafinder function\n",
    "#CES3000000001 - Seasonally Adjusted - Employed and Office of Employment and Unemployment Statistics: Manfacturing - manemp\n",
    "#CUSR0000SA0 - Seasonally Adjusted Consumer Price Index for All Urban Consumers, not including food and energy - cpi_u\n",
    "#CES0000000001 - Seasonally Adjusted - Nonfarm Employment - employment_sa\n",
    "#LNS13000000 - Seasonally Adjusted - Unemployment level in the thousands - unemp_lvl\n",
    "series_id = ['CES3000000001', 'CUSR0000SA0L1E', 'CES0000000001', 'LNS13000000']\n",
    "headers = {'Content-type' : 'application/json'}\n",
    "\n",
    "#designates series and the range of the data and intiates the pull\n",
    "data = json.dumps({\"seriesid\" : series_id, \n",
    "                   \"startyear\": 1998, \"endyear\" : 2011, \n",
    "                   \"registrationkey\": \"ee2f076f1d254305bc09f42aa498afab\"})\n",
    "res = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data = data, headers = headers)\n",
    "json_res = json.loads(res.text)\n",
    "\n",
    "#gets value from the function which is a complete dataframe that has a time range between 1998-2011 \n",
    "left = bls_json(json_res).reset_index(0)\n",
    "\n",
    "#designates series and the range of the data and intiates the pull\n",
    "data = json.dumps({\"seriesid\": series_id,\n",
    "                   \"startyear\": 2012, \"endyear\": 2024,\n",
    "                   \"registrationkey\": \"ee2f076f1d254305bc09f42aa498afab\"})\n",
    "res = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data = data, headers = headers)\n",
    "json_res = json.loads(res.text)\n",
    "\n",
    "gets value from the function which is a complete dataframe that has a time range between 1998-2011\n",
    "right = bls_json(json_res).reset_index(0)\n",
    "\n",
    "#merges the right and left, and then resets the index while subsetting on the columns\n",
    "bls_data = right.merge(left, how = \"outer\")\n",
    "bls_data= bls_data.sort_values(by = \"dates\").reset_index(0)[[\"dates\", \"man_emp\", \"core_cpi\", \"employment\",\"unemp_lvl\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BEA API\n",
    "[BEA API Documentation](https://apps.bea.gov/api/_pdf/bea_web_service_api_user_guide.pdf)\n",
    "\n",
    "API KEY:  A2D2AB50-A251-4378-8CC1-95E51C78615E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives the personal income dataset\n",
    "res = requests.get(\"https://apps.bea.gov/api/data?&UserID=A2D2AB50-A251-4378-8CC1-95E51C78615E&method=GetData&DataSetName=NIPA&TableName=T20600&tableID=ALL&Frequency=M&Year=ALL&ResultFormat=JSON\")\n",
    "personal_income = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>personal_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-01-01</td>\n",
       "      <td>7,368,855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-02-01</td>\n",
       "      <td>7,416,483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>7,464,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>7,501,729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-05-01</td>\n",
       "      <td>7,547,019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>23,230,949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>23,319,690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>23,396,977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>23,627,877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>23,694,328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates personal_income\n",
       "0   1998-01-01       7,368,855\n",
       "1   1998-02-01       7,416,483\n",
       "2   1998-03-01       7,464,033\n",
       "3   1998-04-01       7,501,729\n",
       "4   1998-05-01       7,547,019\n",
       "..         ...             ...\n",
       "309 2023-10-01      23,230,949\n",
       "310 2023-11-01      23,319,690\n",
       "311 2023-12-01      23,396,977\n",
       "312 2024-01-01      23,627,877\n",
       "313 2024-02-01      23,694,328\n",
       "\n",
       "[314 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Makes the dictionary the data would be put into\n",
    "pi_bea = {}\n",
    "pi_bea[\"dates\"] = []\n",
    "pi_bea[\"personal_income\"] = []\n",
    "pi_bea[\"days\"] = []\n",
    "\n",
    "#Looking through the dictionary to find the values of personal income\n",
    "for l in range(0, len(personal_income[\"BEAAPI\"][\"Results\"][\"Data\"])):\n",
    "    if(personal_income[\"BEAAPI\"][\"Results\"][\"Data\"][l].get(\"LineDescription\") == \"Personal income\"):\n",
    "        pi_bea[\"dates\"].append(personal_income[\"BEAAPI\"][\"Results\"][\"Data\"][l].get(\"TimePeriod\"))\n",
    "        pi_bea[\"personal_income\"].append(personal_income[\"BEAAPI\"][\"Results\"][\"Data\"][l].get(\"DataValue\"))\n",
    "        pi_bea[\"days\"].append(\"01\")\n",
    "    \n",
    "#Converts dictionary into dataframe\n",
    "pi_bea = pd.DataFrame(pi_bea)\n",
    "\n",
    "#Since the datetime function requires a specific type of format for the date I would have to append a series of ones \n",
    "#that would concatenated to creat the dates column and the dates column can be converted\n",
    "pi_bea[\"dates\"] = pi_bea[\"dates\"].str[:4] + \"-\" + pi_bea[\"dates\"].str[5:] + \"-\" + pi_bea[\"days\"]\n",
    "pi_bea[\"dates\"] = pd.to_datetime(pi_bea[\"dates\"])\n",
    "\n",
    "#Subsets the data by dates and columns while also resetting the index\n",
    "pi_bea = pi_bea[pi_bea[\"dates\"] > \"1997-12-01\"].reset_index(drop = True)[[\"dates\",\"personal_income\"]]\n",
    "pi_bea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Bureau \n",
    "[Census Bureau API Documentation](https://www.census.gov/content/dam/Census/data/developers/api-user-guide/api-guide.pdf)\n",
    "\n",
    "[Census Bureau API Documentation actual stuff](https://www2.census.gov/data/api-documentation/EITS_API_User_Guide_Dec2020.pdf)\n",
    "\n",
    "API Key: a9c6bd12867708842174babc90f20cfaa20255a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulls all of the data from the M3 survey \n",
    "res = requests.get(\"https://api.census.gov/data/timeseries/eits/m3.json?get=cell_value,data_type_code,time_slot_id,seasonally_adj,category_code,error_data&for=US&time=from+1992-01+to+2024-03&key=a9c6bd12867708842174babc90f20cfaa20255a7\")\n",
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts data ovject into dataframe directly because the values were placed in a list of lists\n",
    "cbs = pd.DataFrame(data, columns = data[0]) \n",
    "\n",
    "#Subsets the data to get values that contribute to total manufacturing\n",
    "cbs = cbs[cbs[\"category_code\"] == \"MTM\"]\n",
    "\n",
    "#Since the datetime function requires a specific type of format for the date I would have to append a series of ones \n",
    "#that would concatenated to creat the dates column and the dates column can be converted\n",
    "cbs[\"dates\"] = cbs[\"time\"] + \"-01\"    \n",
    "cbs[\"dates\"] = pd.to_datetime(cbs[\"dates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsets data by specific data types: Value of Shipments(VS), Finished Inventory(FI), Total Inventory(TI)\n",
    "#Also made sure the data was seasonally adjusted\n",
    "cbs = cbs[((cbs[\"data_type_code\"] == \"VS\") | (cbs[\"data_type_code\"] == \"FI\") | (cbs[\"data_type_code\"] == \"TI\")) & (cbs[\"seasonally_adj\"] == \"yes\")]\n",
    "\n",
    "#subsets the columns to make it easier when combining with later tables\n",
    "cbs = cbs[[\"dates\", \"cell_value\", \"data_type_code\", \"seasonally_adj\", \"category_code\"]].reset_index(drop = True, inplace = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls the csv through the path name\n",
    "consumer = pd.read_csv(\"C:/Users/marvi/Downloads/consumer.csv\")\n",
    "consumer[\"dates\"] = pd.to_datetime(consumer[\"dates\"])\n",
    "consumer = consumer.set_index(consumer[\"dates\"]).shift(freq = '1d')[[\"consumer_confidence\"]].reset_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls the execel sheet through its path name\n",
    "gdp = pd.read_excel(\"C:/Users/marvi/OneDrive/Documents/GitHub/Stock_Markets/excel_sheets/monthly_gdp.xlsx\")\n",
    "gdp[\"dates\"] = pd.to_datetime(gdp[\"dates\"])\n",
    "gdp = gdp[[\"dates\", \"Nominal_GDP_Index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>consumer_confidence</th>\n",
       "      <th>Nominal_GDP_Index</th>\n",
       "      <th>man_emp</th>\n",
       "      <th>core_cpi</th>\n",
       "      <th>employment</th>\n",
       "      <th>unemp_lvl</th>\n",
       "      <th>personal_income</th>\n",
       "      <th>days</th>\n",
       "      <th>ff_rate</th>\n",
       "      <th>VS</th>\n",
       "      <th>FI</th>\n",
       "      <th>TI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-02-01</td>\n",
       "      <td>106.6</td>\n",
       "      <td>8772.700661</td>\n",
       "      <td>17627.0</td>\n",
       "      <td>171.900</td>\n",
       "      <td>125018.0</td>\n",
       "      <td>6306.0</td>\n",
       "      <td>7,416,483</td>\n",
       "      <td>01</td>\n",
       "      <td>5.557419</td>\n",
       "      <td>329617</td>\n",
       "      <td>153489</td>\n",
       "      <td>447466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-03-01</td>\n",
       "      <td>110.4</td>\n",
       "      <td>8894.547995</td>\n",
       "      <td>17637.0</td>\n",
       "      <td>172.200</td>\n",
       "      <td>125164.0</td>\n",
       "      <td>6422.0</td>\n",
       "      <td>7,464,033</td>\n",
       "      <td>01</td>\n",
       "      <td>5.505714</td>\n",
       "      <td>328480</td>\n",
       "      <td>153966</td>\n",
       "      <td>448486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-04-01</td>\n",
       "      <td>106.5</td>\n",
       "      <td>8932.191344</td>\n",
       "      <td>17637.0</td>\n",
       "      <td>172.500</td>\n",
       "      <td>125445.0</td>\n",
       "      <td>5941.0</td>\n",
       "      <td>7,501,729</td>\n",
       "      <td>01</td>\n",
       "      <td>5.493548</td>\n",
       "      <td>324127</td>\n",
       "      <td>153449</td>\n",
       "      <td>449663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-05-01</td>\n",
       "      <td>108.7</td>\n",
       "      <td>8925.512418</td>\n",
       "      <td>17624.0</td>\n",
       "      <td>172.900</td>\n",
       "      <td>125846.0</td>\n",
       "      <td>6047.0</td>\n",
       "      <td>7,547,019</td>\n",
       "      <td>01</td>\n",
       "      <td>5.445333</td>\n",
       "      <td>326081</td>\n",
       "      <td>153687</td>\n",
       "      <td>450268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>106.5</td>\n",
       "      <td>8953.129642</td>\n",
       "      <td>17608.0</td>\n",
       "      <td>173.200</td>\n",
       "      <td>126077.0</td>\n",
       "      <td>6212.0</td>\n",
       "      <td>7,584,421</td>\n",
       "      <td>01</td>\n",
       "      <td>5.488710</td>\n",
       "      <td>318990</td>\n",
       "      <td>153379</td>\n",
       "      <td>451186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>71.5</td>\n",
       "      <td>27386.299100</td>\n",
       "      <td>12941.0</td>\n",
       "      <td>309.656</td>\n",
       "      <td>156421.0</td>\n",
       "      <td>6340.0</td>\n",
       "      <td>23,094,503</td>\n",
       "      <td>01</td>\n",
       "      <td>5.120000</td>\n",
       "      <td>585976</td>\n",
       "      <td>298064</td>\n",
       "      <td>855320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>69.4</td>\n",
       "      <td>27624.369911</td>\n",
       "      <td>12954.0</td>\n",
       "      <td>310.644</td>\n",
       "      <td>156667.0</td>\n",
       "      <td>6347.0</td>\n",
       "      <td>23,176,244</td>\n",
       "      <td>01</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>585918</td>\n",
       "      <td>298548</td>\n",
       "      <td>856463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>67.8</td>\n",
       "      <td>27828.287502</td>\n",
       "      <td>12923.0</td>\n",
       "      <td>311.390</td>\n",
       "      <td>156832.0</td>\n",
       "      <td>6443.0</td>\n",
       "      <td>23,230,949</td>\n",
       "      <td>01</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>578039</td>\n",
       "      <td>298530</td>\n",
       "      <td>856465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>63.8</td>\n",
       "      <td>27742.860313</td>\n",
       "      <td>12948.0</td>\n",
       "      <td>312.349</td>\n",
       "      <td>157014.0</td>\n",
       "      <td>6262.0</td>\n",
       "      <td>23,319,690</td>\n",
       "      <td>01</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>580730</td>\n",
       "      <td>298333</td>\n",
       "      <td>856730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>61.3</td>\n",
       "      <td>27779.831764</td>\n",
       "      <td>12960.0</td>\n",
       "      <td>313.209</td>\n",
       "      <td>157304.0</td>\n",
       "      <td>6268.0</td>\n",
       "      <td>23,396,977</td>\n",
       "      <td>01</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>578048</td>\n",
       "      <td>298396</td>\n",
       "      <td>856616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates  consumer_confidence  Nominal_GDP_Index  man_emp  core_cpi  \\\n",
       "0   1998-02-01                106.6        8772.700661  17627.0   171.900   \n",
       "1   1998-03-01                110.4        8894.547995  17637.0   172.200   \n",
       "2   1998-04-01                106.5        8932.191344  17637.0   172.500   \n",
       "3   1998-05-01                108.7        8925.512418  17624.0   172.900   \n",
       "4   1998-06-01                106.5        8953.129642  17608.0   173.200   \n",
       "..         ...                  ...                ...      ...       ...   \n",
       "306 2023-08-01                 71.5       27386.299100  12941.0   309.656   \n",
       "307 2023-09-01                 69.4       27624.369911  12954.0   310.644   \n",
       "308 2023-10-01                 67.8       27828.287502  12923.0   311.390   \n",
       "309 2023-11-01                 63.8       27742.860313  12948.0   312.349   \n",
       "310 2023-12-01                 61.3       27779.831764  12960.0   313.209   \n",
       "\n",
       "     employment  unemp_lvl personal_income days   ff_rate      VS      FI  \\\n",
       "0      125018.0     6306.0       7,416,483   01  5.557419  329617  153489   \n",
       "1      125164.0     6422.0       7,464,033   01  5.505714  328480  153966   \n",
       "2      125445.0     5941.0       7,501,729   01  5.493548  324127  153449   \n",
       "3      125846.0     6047.0       7,547,019   01  5.445333  326081  153687   \n",
       "4      126077.0     6212.0       7,584,421   01  5.488710  318990  153379   \n",
       "..          ...        ...             ...  ...       ...     ...     ...   \n",
       "306    156421.0     6340.0      23,094,503   01  5.120000  585976  298064   \n",
       "307    156667.0     6347.0      23,176,244   01  5.330000  585918  298548   \n",
       "308    156832.0     6443.0      23,230,949   01  5.330000  578039  298530   \n",
       "309    157014.0     6262.0      23,319,690   01  5.330000  580730  298333   \n",
       "310    157304.0     6268.0      23,396,977   01  5.330000  578048  298396   \n",
       "\n",
       "         TI  \n",
       "0    447466  \n",
       "1    448486  \n",
       "2    449663  \n",
       "3    450268  \n",
       "4    451186  \n",
       "..      ...  \n",
       "306  855320  \n",
       "307  856463  \n",
       "308  856465  \n",
       "309  856730  \n",
       "310  856616  \n",
       "\n",
       "[311 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of the Dataframes created in this notebook\n",
    "list_frames = [gdp, consumer, bls_data, pi_bea, dt_fr_avg]\n",
    "\n",
    "#List of the Column names that would be in Census Bureau dataset\n",
    "list_cbs_cl = [\"VS\", \"FI\", \"TI\"]\n",
    "\n",
    "#iterates through the list of dataframes and joins them sequentially\n",
    "for i in range(0, len(list_frames)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    elif i == 1:\n",
    "        df1 = pd.merge(list_frames[i], list_frames[i-1])\n",
    "    elif i > 1 & i <= 4:  \n",
    "        df1 = pd.merge(df1, list_frames[i])\n",
    "\n",
    "#Iterates through the columns to create a new dataframe from somewhat cleaned sensus buearu dataframe from earlier\n",
    "#After creating the new dataframe it would have its column renamed and then joined with the dataframe above\n",
    "for j in range(0, len(list_cbs_cl)):\n",
    "    df2 = cbs[(cbs[\"data_type_code\"] == list_cbs_cl[j]) & (cbs[\"category_code\"] == \"MTM\") & (cbs[\"seasonally_adj\"] == \"yes\")]\n",
    "    df2 = df2[[\"dates\", \"cell_value\"]].reset_index(drop = True, inplace = False).rename(columns = {\"cell_value\":list_cbs_cl[j]})\n",
    "    df1 = pd.merge(df1, df2, on = \"dates\")\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Regression(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### y(GDP, Employment Level)<sub>t</sub> = GDP<sub>t-k</sub> + Employment<sub>t-k</sub> \n",
    "##### y(Value of Shipments, Employment Level)<sub>t</sub> = Value of Shipments<sub>t-k</sub> + Manufacturing Employment<sub>t-k</sub>\n",
    "Based off the law made by Okun, I will working off the assumption that a change in employment would induce a change in output \n",
    "\n",
    "- These would be Vectorautoregressions(VAR) that depicts relationship between output and employment. I will be using Gross Domestic Product and both Employment Levels and Unemployment Levels and that will help detemine if the relationship can be seen in the general economy. Then there will also be a model for specifically the manufacturing industry, that would make use of value of shipments as the measure of output and manufacturing employment levels\n",
    "- Utilizes monthly data of employment and inflation adjusted GDP values\n",
    "- After running the VAR, I will use a granger causality test to determine the predictiveness of both variables and their respective lags \n",
    "- Following the granger test, I will make use of a impulse response function to determine the effects over multiple periods\n",
    "\n",
    "\n",
    "##### Value of Shipments<sub>t</sub> = Manufacturing Employment<sub>t</sub> + Personal Income<sub>t</sub> + Baltic Dry Index<sub>t</sub> + Federal Funds Rate<sub>t</sub>\n",
    "This is a time series regressions that predicts how the value of shipments change. Based off the results from the VAR and the underlying tests, I would determine if a lag in manufacturing employment affects the value of shipments at time *t*. One assumption I make is that as factory owners recognize that in maximizing output there would need to be an increase in labor. That would potentially hurt the objective of maximizing profit, so the firm may purchase technology that would produce marginally lower expenses than an employee and increase potential output. Additionally, a decrease in national personal income may affect the value of shipments as more people save rather than consume. Shifts in the demand for the materials to produce would affect the values of shipments as well considering that the industry may need those inputs. Finally the movements and expectations around monetary policy would shift the movements of the market and potentially affect the worth of those shipments     \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
